В 2012 году Почта России столкнулась с нехваткой масштабируемости и управляемости в интеграциях между цифровыми сервисами, что мешало внедрению новых сервисов.
Изначально вся интеграция шла через full mesh что создавало сложности во внедрений, в прогрессий создавать комбинаторику пар для каждого сервиса в перспективе делает её очень не выгодной(10 сервисов = 45 связей, 100 сервисов = 5000 связей). Что делает процесс муторным и требует согласования с каждым участком в стране.
Причины выбора Kafka
Требовалось:
1) Open source решение
2) Высокая масштабируемость
3) Отказоусточивость(сломается в одном участке сломается везде что было недопустимо)
4) Возможность обогощение данных
5) Пропускная способность 1млн сообщений в секунду
Выбор был между: Kafka, AMQ, RMQ

| Критерий                      | Kafka                                          | RabbitMQ                                         | ActiveMQ (AMQ)                                     |
| ----------------------------- | ---------------------------------------------- | ------------------------------------------------ | -------------------------------------------------- |
| Масштабируемость              | Легко масштабируется горизонтально             | Ограниченная масштабируемость                    | Ограниченная масштабируемость                      |
| Переносимость данных          | Журнал событий на диск (commit log)            | Требует настройки durable queues                 | Требует настройки для persistent сообщений         |
| Производительность            | Очень высокая                                  | Средняя при больших нагрузках                    | Средняя                                            |
| High Availability (HA)        | Встроенная репликация топиков                  | Требует ручной настройки кластеров и federation  | Требует настройку Master-Slave или Shared Store HA |
| Интеграция с Big Data         | Нативная (Kafka → Hadoop, Spark, Flink)        | Ограниченная                                     | Слабая интеграция                                  |
| Работа с большими сообщениями | Через внешнее файловое хранилище + ссылка      | Плохо справляется с сообщениями > 1MB            | Плохо справляется с большими сообщениями           |
| Управляемость                 | Достаточно простая через стандартные средства  | Сложная при росте нагрузки                       | Сложная при росте нагрузки                         |
| Надёжность доставки           | Очень высокая за счёт репликации и commit log  | Требует настройки durable queues и подтверждений | Требует настройки персистентных очередей           |
| Подходящая задача             | Потоковая обработка событий в реальном времени | Очереди задач, RPC взаимодействие                | Очереди задач, Enterprise Integration Patterns     |

Вывод: для задач, требующих высокой пропускной способности, горизонтальной масштабируемости, долговременного хранения событий и интеграции с Big Data — Kafka на голову выше RabbitMQ и ActiveMQ.

После выбора самой "шины" требовалось расширить функционал под задачи для чего были добавлены:
1) API Gateway - написан на java, аутентифицирует клиентов (по токенам JWT), проверяет права доступа, контролирует лимиты
2) Proxy - REST, упрощает внешние интеграций, делает kafka невидимой для клиентов
3) Файловое хранилище - kafka плохо работает с данными > 1 mb, поэтому если файл больше mb, то сохраняется в файловое хранилище а kafka содержит только ссылку на файл
4) Трансформатор данных - на основе Apache Samza, Apache Camel проводит данные через консьюмер и приводит их к согласованной форме
5) Мониторинг - для мониторинга использовался стек Prometheus(сбор метрик), Grafana(построение дашбордов), Elasticsearch + Kibana(централизованная система логирования), Alertmanager(оповещения при нарушениях SLA), Отказоустоичивость: 99.999%
Architecture:
![Uploading Kafka-architecture.png…]()


Технические характеристики:
1) 3 собственных дата-центра.
2) 98 серверов bare-metal:
     82 ядра (с hyper-threading).
     386GB RAM.
     20TB дисковое пространство на сервер.
3) Network bonding для увеличения пропускной способности сети.
4) Загрузка сети: в среднем 2 Гбит/с, пики до 78 Гбит/с.
5) 40 000 клиентов Kafka (producers + consumers).

Производительность:
1) До 3 миллионов сообщений в секунду в пиковых нагрузках (при обработке Big Data).
2) Средняя нагрузка — 500k – 1M сообщений в секунду.

Оптимизация производительности:
1) Выделенные сервера без виртуализации.
2) Выделенные сетевые контуры.
3) Тюнинг параметров Kafka

| **Плюсы**                                                                                               | **Минусы**                                                                                              |
| ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| Существенное упрощение интеграций (сокращение времени внедрения с месяцев до дней)                      | Единая точка отказа (если шина упадёт — упадут все сервисы)                                             |
| Высокая надёжность и отказоустойчивость из коробки (репликации Kafka)                                   | Может стать bottleneck (ограничение пропускной способности команды интеграции)                          |
| Сервис-ориентированная архитектура (SOA), упрощение создания новых сервисов                             | Высокая стоимость внедрения и поддержки инфраструктуры                                                  |
| Перенос ответственности за работу с данными на центральную инфраструктуру (разгрузка команд приложений) | Очень высокие требования к сетевому оборудованию и дата-центрам                                         |
| Высокая скорость обработки данных (до 3 миллионов сообщений в секунду)                                  | Ломает коммуникацию между командами (отсутствие прямой договорённости между продюсерами и консьюмерами) |

Дополнительные детали:
Криптография регуляторов (ФСБ) отдельно, не через Kafka.    
Асинхронные API по умолчанию, проблем с синхронными API нет.
Нет планов на переход на full-flash.
План перехода с Apache Kafka на Confluent Kafka.
Перевод данных в Avro-формат для контрактов.
Не проводят регулярных нагрузочных тестов — реальная нагрузка стабильная.
Данные в Kafka хранятся месяцами и годами в зависимости от законодательства.
Планируется сделать архитектуру менее централизованно
