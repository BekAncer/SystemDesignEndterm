ВКонтакте сталкивается с необходимостью обработки колоссального сетевого трафика:
1) Полтора миллиона запросов в секунду на API.
2) Столько же запросов на отдачу изображений.
3) Суммарно — несколько терабит сетевого трафика.

Проблема в том что классический подход HTTP/1.1 не справляется:
1) Много параллельных запросов = много TLS-соединений = высокая нагрузка на девайсы и сервера.
2) Возникает проблема head-of-line blocking(блокировка канала при потере одного пакета).


Причины перехода к QUIC:
1. Убрать head-of-line blocking на уровне транспорта.
2. Переместить шифрование (TLS) ниже — на транспортный уровень.
3. Повысить производительность и уменьшить время установки соединений.
4. Обеспечить независимые стримы на уровне транспорта.
5. Поддержка смены IP без обрыва сессии (connection migration).
6. Минимизация потерь данных и оптимизация восстановления пакетов.

По итогу:
1) HTTP/2 частично решал проблему, но был всё ещё основан на TCP, где head-of-line blocking остаётся.
2) Появился новый протокол **QUIC**, разработанный Google: передача данных через UDP, надёжность, шифрование и мультистриминг встроены в транспорт.

HTTP/1.1 vs HTTP/2 vs QUIC:

| Критерий                       | HTTP/1.1                           | HTTP/2                         | QUIC                             |
| ------------------------------ | ---------------------------------- | ------------------------------ | -------------------------------- |
| Транспортный протокол          | TCP                                | TCP                            | UDP                              |
| Multiplexing                   | Нет (одно соединение = один поток) | Есть, но head-of-line blocking | Есть, без head-of-line blocking  |
| Шифрование встроено            | Нет                                | Нет                            | Да (TLS 1.3 встроен в транспорт) |
| Устойчивость к смене IP        | Нет                                | Нет                            | Да (connection migration)        |
| Ускорение установки соединений | Нет                                | Нет                            | Да (объединённый handshake)      |
| Приоритеты стримов             | Нет                                | Есть                           | Есть                             |
| Использование в реальных сетях | Высокое                            | Среднее                        | Быстро растущее использование    |

Вывод: **QUIC** устраняет ограничения TCP и подходит для высоконагруженных приложений современного интернета.

Расширение стандартного функционала:
После внедрения QUIC в ВКонтакте были доработки:
1. Server-side реализация: использование Nginx QUIC (форк с модификациями под VK), доработка для устойчивости к нагрузке и failover'ам.
2. Оптимизация передачи данных: переход на системные вызовы типа `sendmmsg()` и `recvmmsg()`, batch-отправка пакетов для снижения системных вызовов, настройка socket options для контроля пассинга пакетов (отложенная отправка).
3. Балансировка на уровне ядра: использование eBPF для балансировки новых соединений по воркерам через cookie socket ID.
4. MTU Discovery: автоматическое определение максимально допустимого размера пакета для минимизации фрагментации.
5. Тюнинг congestion control: переписка старого congestion control, использование новых алгоритмов (например, BBR вместо Reno).
6. Контроль flow control и congestion control: разделение задач: flow control = приём данных на конечной точке, congestion control = контроль трафика в сети.

Архитектура решения:

![Backend-Optimization](https://github.com/user-attachments/assets/cfdd9b90-35a3-462e-a328-4c65a9d54250)

Технические характеристики
1. 530 frontend серверов (контент, API).
2. 4000+ PHP серверов (логика).
3. SIDN (локальные CDN узлы) для отдачи картинок ближе к пользователю.
4. Использование eBPF для балансировки.
5. Разработка и доработка собственной реализации Nginx-QUIC.


Производительность
1. Ускорение работы сайта за счёт уменьшения задержек.
2. Существенное снижение нагрузки на процессоры и сеть.
3. Прирост трафика на backend ≈ +30% из-за увеличения скорости потребления контента.
4. Минимизация фрагментации сетевых пакетов.

Оптимизация производительности
1. Использование batch system calls (`sendmmsg()`, `recvmmsg()`).
2. Контроль размера пакетов (MTU Discovery).
3. Индивидуальный flow control для каждого стрима.
4. Улучшенные congestion control алгоритмы.
5. Балансировка соединений на уровне ядра через eBPF.

## Плюсы и минусы решения

| **Плюсы**                                                                              | **Минусы**                                                                |
| -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| Устранение head-of-line blocking                                                       | Новый протокол = высокая начальная сложность внедрения                    |
| Высокая производительность, уменьшение задержек                                        | Зависимость от поддержки QUIC у клиентов (браузеры, операционные системы) |
| Поддержка connection migration                                                         | Возможность блокировки на уровне операторов связи                         |
| Упрощённое шифрование (TLS вшит в транспорт)                                           | Требует доработки балансировки и тюнинга ядра (eBPF)                      |
| Гибкость благодаря UDP (можно оптимизировать flow control, congestion control вручную) | Высокий риск при внедрении (ошибки могут положить всю сеть)               |

Дополнительные детали:
Если сервер или клиент не поддерживает QUIC — происходит fallback на TCP/TLS.  
Построены безопасные механизмы отката соединений.
Реализация выложена в открытый доступ (форк Nginx с VK-правками).
Протокол даёт до **3x прироста** в скорости передачи данных в сравнении с TCP + HTTP/2.
Активно работают над будущими улучшениями: interleaving, защита от DDoS на уровне transport-layer.
