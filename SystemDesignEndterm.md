# Task1
![[![task1](https://github.com/user-attachments/assets/4be8dbf8-1779-4f2c-b09b-4d823a1f5131)]]
Функциональные требования:
1) Сбор кликов, лайков, комментов, реклам от юзеров
2) Потоковая агрегация данных
3) Вычисление метрик в near-real-time
4) Визуализация данных

Нефункциональные требования:
1) Availability: 99.9%
2) Fault Tolerance
3) Latency: 10 sec
4) RPS ~3K
5) CP, важна согласованность данных

Dataflow:
1) Пользователи (веб или мобильное приложение) взаимодействуют с системой, эти события передаются в event collector как fire
2) Коллектор валидирует данные и отправляет в Kafka
3) Kafka разделяет по топикам и асинхронно отправляет по сервисам
4) В gateway логирует метрики событий (OpenTelemetry)
5) Flink Job Manager выполняет потоковую агрегацию и вычисления и передает результаты в Redis, OLAP, DataLake
6) Spark использует datalake для обучения ml models
7) Analytics-API cервис FastAPI, агрегирует данные из ClickHouse и Redis, также может обращаться к ML
8) Dashboards отображают метрики в реальном времени
9) Observability: метрики трейсы, логи

# Task2
![[[task2](https://github.com/user-attachments/assets/ff58d0dc-5a4d-4cdd-906d-9395fa4ce719)]]!

Функциональные требования:
1) Обработка запросов на поездку от пассажиров
2) Динамическое планирование маршрутов 
3) Перераспределение транспорта в зависимости от нагрузки
4) Интеграция с системой городского трафика (данные о пробках, ДТП, закрытых дорогах)
5) Мониторинг состояния автономных автобусов (топливо. тех состояние)
6) Интерфейс для диспетчеров и аналитиков
7) Уведомления для пассажиров

Нефункциональные требования:
1) Безопасность
2) Низкая задержка
3) Availability: 99.9%
4) Fault Tolerance
5) AP, consistency eventually
6) Observability
7) RPS ~ (200000*10000)/(24 * 60 * 60) => 23K RPS, peak 70K RPS

Dataflow:
1) Users → Mobile App
	Пассажир делает запрос: хочет поехать от точки A до точки B.
2) API Gateway → Kafka 
	Событие поступает в Kafka откуда его может подписываться RouteOptimization Service.
3) Kafka → OLAP (ClickHouse) 
	Параллельно данные об инциденте/запросе пишутся в ClickHouse для последующего анализа поведения пассажиров, пиков нагрузки
4) Kafka → RouteOptimizationService
	Сервис получает событие поездки и начинает оптимизировать: какой автобус и когда обслужит этот запрос, как проложить маршрут.
5) RouteOptimizationService → RoutesMapAPI
	Получение маршрутов между точками, возможных путей, расстояний
6) RouteOptimizationService → TrafficCongestion API
	Получение трафиковой ситуации в реальном времени (пробки, ДТП, ремонт дорог). Это может быть интеграция с городской системой.
7) RouteOptimizationService → DepotService 
	Проверка доступности автобусов на стоянках: какие готовы, заряжены, свободны, где находятся.
8) RouteOptimizationService → ML-модель Route Builder
	Используется предсказательная модель: на основе истории поездок, плотности пассажиров, времени и событий система получает рекомендации о маршрутах и их вероятной загруженности.
9) TrafficCongestion API → IoT
	Получать доп. данные с камер, сенсоров, парковочных датчиков, LIDAR, и т.п., установленных на транспорте и в городе.
10) IoT → SafetyCheckAPI
	Сенсоры передают информацию о возможных рисках. SafetyCheckAPI агрегирует это и генерирует оповещения. 
11) SafetyCheckAPI → Dashboard (admin panel)
	Оповещения, телеметрия, состояние автобусов и логика маршрутов передаются в админ-панель для диспетчеров. Она позволяет:
	-Вмешаться вручную при необходимости
	-Смотреть на загруженность
	-Получать предупреждения об инцидентах


# Task3
![[![task3](https://github.com/user-attachments/assets/0cd67c2c-d3bf-421f-bd44-7695e84e80c3)
]]
Функциональные требования:
1) Регистрация студентов и работодателей
2) Загрузка профиля студента (CV, документы о гражданстве, визах и т.п.)
3) Публикация стажировок работодателями
4) Механизм подачи заявок студентам
5) Проверка документов на подлинность
6) Автоматическая проверка соответствия стажировки миграционным требованиям
7) Чат/переписка между студентом и компанией
8) Уведомления о статусах заявок
9) Интеграция с внешними API для валидации паспортов/виз

Нефункциональные требования:
1) Высокая доступность
2) Безопасность
3) Задержка <300ms
4) Удобное масштабирование

Dataflow:
1) Регистрация и логин студента / работодателя:
	1. Пользователь отправляет данные на регистрацию или логин.
	2. API Gateway проксирует запрос в AuthService
	3. AuthService записывает пользователя в UsersDB или проверяет его.
	4. Если регистрация успешна — в Kafka публикуется событие
	5. NotificationService, подписанный на Kafka, отправляет e-mail/push приветствие.
2) Создание профиля:
	1. После логина пользователь заполняет профиль.
	2. Gateway отправляет данные в ProfileService.
	3. Профиль сохраняется в UsersDB.
3) Публикация стажировки работодателем:
	1. Работодатель создаёт стажировку.
	2. Gateway пересылает в InternshipService.
	3. InternshipService сохраняет стажировку
4) Подача заявки на стажировку
	1. Студент нажимает "подать заявку".
	2. Gateway отправляет запрос в ApplicationService.
	3. ApplicationService:
	   сохраняет заявку в ApplicationDB;
	   публикует событие в Kafka;
	   вызывает VerificationService.
5) Верификация документов и виз
    1. VerificationService получает данные.
    2. Делает вызовы к DocumentsVerifAPI и VISAVerifAPI.
    3. Возвращает результат в ApplicationService
    4. ApplicationService обновляет статус заявки.
# Task5
![[![task5](https://github.com/user-attachments/assets/6710630c-827b-4f83-8718-e84ff07ce8df)
]]
Функциональные требования:
1) Голосование онлайн; 
2) Проверка, что голос учтен; 
3) Возможность проверки честности выборов

Нефункциональные требования:
1) Анонимность голосов
2) Безопасность
3) Отказоустойчивость
4) Прозрачность
5) Защита от DDoS
6) RPS: 20000000 / (24 * 60 * 60)  ~ 231 RPS, Peak RPS: 500 RPS
7) CP, лучше отказать в возможности голоса чем проголосовать с возможной нестабильностью

Dataflow:
1) User Device — открывается приложение и делается HTTPS запрос.
2) CDN/WAF — проверка на DDoS, фильтрация аномалий.
3) API Gateway — авторизация запроса, защита от ботов.
4) Authentication Service:
	Проверяет личность избирателя.
	Выдает один токен для голосования.        
5) Voting Service:
	Принимает голос по токену.
	Сохраняет голос в PostgreSQL
	Отправляет запись в LedgerService.
6) LedgerService: 
	Пишет публичную транзакцию на Blockchain. 
7) AuditService:
    Показывает публичную статистику голосования и аудита в реальном времени.
8) BackupSystem:
	Каждые 5 минут делает копию всех новых голосов.
	

# Task6
![[![task6](https://github.com/user-attachments/assets/271c80cc-9132-40dd-9d68-51b01d378435)
]]
Функциональные требования:
1) Регистрация и Авторизация пользователей по биометрике
2) Размер и запись выдачи
3) проверка справедливости распределения
4) Возможность локальной работы
5) Синхронизация данных
6) Децентрализация


Нефункциональные требования:
1) Бесперебойная доступность
2) Безопасность данных
3) Устойчивость к мошенничеству и ошибкам
4) Прозрачность операций
5) AP, консистентность восстанавливается при подключений к сети 

Dataflow:
Волонтёр через Mobile App:
	сохраняет биометрику
	Создаёт или связывает Decentralized ID (DID).
	Все данные шифруются локально в Local Storage.
	Приложение фиксирует событие в локальную очередь синхронизации.
	Пользователь получает свой QR-код или цифровую карточку.
Sync Service Постоянно проверяет наличие интернета.
	При появлении связи — начинает выгрузку событий.
Отправляет данные через API Gateway. API подтверждает успешную загрузку каждой транзакции.
	Данные проходят через DID Identity: Проверяется валидность цифрового ID и подписи.  Проходит через Biometric Matcher: Выполняется поиск по существующим биометрическим данным.
После базовой проверки: Событие отправляется в брокер **Kafka/NATS** (асинхронно).
	Conflict Resolver Workers: Разрешают возможные конфликты данных (например, два волонтёра зарегистрировали одного и того же человека в разное время).
После разрешения: События записываются в Cassandra (структурированные данные о получателях, выдачах помощи).

При новой выдаче:
	Волонтёр сканирует ID получателя через приложение.
	Приложение локально проверяет данные, если возможно.
	При наличии интернета проверяется с сервером (в случае обновлений или конфликтов).

Операция выдачи:
	Локально логируется.
	Потом через Sync Service отправляется в центральную систему.
	 Выдачи также проходят через Kafka для дальнейшего анализа.
Audit Service:
	Периодически агрегирует события из базы данных.
	Где были подозрительные активности (например, один ID получил помощь в двух местах одновременно).
UN Portal:
	Доступ для сотрудников ООН/NGO с правами только на чтение.
	Возможность выгружать отчёты, смотреть карты распределения помощи.

